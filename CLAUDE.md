# Claude Code Configuration

## A Savoir :
- le MCP Playwright est installÃ©, sers-t'en!
- **Lis la doc dans `/docs`** - Structure organisÃ©e par composant (CLI, WebApp, Tooling)
- **IMPORTANT : Sous WSL, utiliser `python3` et non `python`**
- Les tests sont dans `/CLI/tests` et utilisent pytest

## âš ï¸ Configuration Critique

**Le fichier `.sdgen_config.json` DOIT Ãªtre dans le home directory (`~/.sdgen_config.json`) !**

```bash
# CrÃ©er/modifier la config
sdgen init

# Fichier crÃ©Ã© : ~/.sdgen_config.json
# Contenu :
{
  "configs_dir": "/path/to/your/templates",
  "output_dir": "/path/to/output",
  "api_url": "http://127.0.0.1:7860"
}
```

**NE PAS** mettre la config dans le dossier du projet, elle ne sera pas trouvÃ©e depuis d'autres rÃ©pertoires.

## ğŸ“ Structure du Projet

Le projet utilise la **structure src/ layout** (meilleure pratique Python moderne) :

```
local-sd-generator/
â”œâ”€â”€ CLI/                    # Package CLI (gÃ©nÃ©rateur SD)
â”‚   â”œâ”€â”€ src/               # Code source (PYTHONPATH configurÃ© sur src/)
â”‚   â”‚   â”œâ”€â”€ api/          # Client API SD WebUI
â”‚   â”‚   â”œâ”€â”€ templating/   # Template System V2.0
â”‚   â”‚   â”‚   â”œâ”€â”€ models/         # Data models (TemplateConfig, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ loaders/        # YAML loading & parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ validators/     # Template validation
â”‚   â”‚   â”‚   â”œâ”€â”€ resolvers/      # Inheritance, imports, template resolution
â”‚   â”‚   â”‚   â”œâ”€â”€ generators/     # Prompt generation (combinatorial/random)
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizers/    # Prompt normalization
â”‚   â”‚   â”‚   â”œâ”€â”€ utils/          # Hash & path utilities
â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.py # V2Pipeline main orchestrator
â”‚   â”‚   â”œâ”€â”€ config/       # Configuration globale
â”‚   â”‚   â””â”€â”€ execution/    # ExÃ©cution et orchestration
â”‚   â”œâ”€â”€ tests/            # Tests unitaires et d'intÃ©gration
â”‚   â”‚   â”œâ”€â”€ api/          # Tests API client (76 tests)
â”‚   â”‚   â”œâ”€â”€ templating/   # Tests parsing V2 (3 tests)
â”‚   â”‚   â”œâ”€â”€ v2/           # Tests V2 complets (227 tests)
â”‚   â”‚   â”‚   â”œâ”€â”€ unit/           # Tests unitaires
â”‚   â”‚   â”‚   â””â”€â”€ integration/    # Tests d'intÃ©gration
â”‚   â”‚   â””â”€â”€ legacy/       # Anciens tests fonctionnels
â”‚   â”œâ”€â”€ src/cli.py        # Point d'entrÃ©e CLI (Typer)
â”‚   â””â”€â”€ pyproject.toml    # Configuration package CLI
â”œâ”€â”€ backend/              # Backend FastAPI (anciennement /api/)
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ front/                # Frontend (si existant)
â”œâ”€â”€ venv/                 # Virtual environment Python
â””â”€â”€ docs/                 # Documentation
```

**Note importante** : Le dossier backend Ã©tait anciennement nommÃ© `/api/`, ce qui crÃ©ait un conflit de noms avec `/CLI/src/api/`. Il a Ã©tÃ© renommÃ© en `/backend/` pour Ã©viter les problÃ¨mes d'imports Python.

## ğŸ¯ Template System V2.0

Le systÃ¨me de templates V2.0 est le **seul systÃ¨me actif** du projet.

**FonctionnalitÃ©s principales:**
- ğŸ”— **Inheritance** - HÃ©ritage avec `implements:` (multi-niveau)
- ğŸ“¦ **Modular imports** - Imports avec `imports:` (fichiers YAML ou strings inline)
- ğŸ§© **Reusable chunks** - Chunks rÃ©utilisables avec `chunks:`
- ğŸ² **Advanced selectors** - `[random:N]`, `[limit:N]`, `[indexes:1,5,8]`, `[keys:foo,bar]`
- âš–ï¸ **Weight-based loops** - ContrÃ´le de l'ordre des boucles avec `weight:`
- ğŸ¨ **Generation modes** - Combinatorial (toutes combinaisons) ou Random (Ã©chantillonnage)
- ğŸŒ± **Seed modes** - Fixed, Progressive, Random

**V1 (Phase 2) status:** âŒ SupprimÃ© (migration complÃ¨te vers V2)

## ğŸ Python Environment Setup

### Virtual Environment
Le projet utilise un venv Linux (`venv/`) Ã  la racine du projet :

```bash
# CrÃ©er le venv (dÃ©jÃ  fait)
python3 -m venv venv

# Activer le venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install pyyaml requests pytest pytest-cov

# DÃ©sactiver
deactivate
```

**Note:** Ne PAS utiliser `.venv/` (venv Windows verrouillÃ© sous WSL).

### Running Tests

**IMPORTANT:**
- **TOUJOURS activer le venv d'abord** : `source venv/bin/activate` (depuis la racine du projet)
- Toujours utiliser `python3 -m pytest` (pas `python` ni `pytest` directement)
- Pytest 8.x requiert des `__init__.py` dans tous les dossiers de tests (structure package-based)

```bash
# Ã‰TAPE 1 : Activer le venv (depuis la racine du projet)
cd /mnt/d/StableDiffusion/local-sd-generator
source venv/bin/activate

# Ã‰TAPE 2 : Aller dans /CLI
cd CLI

# Ã‰TAPE 3 : Lancer les tests

# Tests V2 complets (227 tests) - 96.5% de rÃ©ussite
python3 -m pytest tests/v2/ -v

# Tests API client (76 tests) - 100% âœ…
python3 -m pytest tests/api/ -v

# Tests templating/parsing (3 tests) - 100% âœ…
python3 -m pytest tests/templating/ -v

# Tous les tests (sans legacy)
python3 -m pytest tests/ --ignore=tests/legacy -v

# Avec couverture de code (pytest-cov)
python3 -m pytest tests/v2/ --cov=templating --cov-report=term-missing -v
```

**Alternative sans activer le venv (moins pratique) :**
```bash
cd /mnt/d/StableDiffusion/local-sd-generator/CLI
../venv/bin/python3 -m pytest tests/v2/ -v
```

**Structure des tests :**
```
CLI/tests/
â”œâ”€â”€ api/               # Tests API client (76 tests) âœ…
â”œâ”€â”€ templating/        # Tests parsing V2 (3 tests) âœ…
â”œâ”€â”€ v2/                # Tests V2 systÃ¨me (227 tests) ğŸŸ¢ 96.5%
â”‚   â”œâ”€â”€ unit/          # Tests unitaires (gÃ©nÃ©rateurs, resolvers, etc.)
â”‚   â””â”€â”€ integration/   # Tests d'intÃ©gration (API, executor)
â”œâ”€â”€ integration/       # Tests d'intÃ©gration globaux
â””â”€â”€ legacy/            # Anciens tests fonctionnels
```

**Total : 306 tests (300 passent - 98%)**

**Pourquoi `python3 -m pytest` ?**
- `pytest` seul ne dÃ©tecte pas toujours le bon PYTHONPATH
- `python3 -m pytest` ajoute le rÃ©pertoire courant automatiquement
- RÃ©sout les `ModuleNotFoundError` dans les imports
- Sous WSL, toujours utiliser `python3` et pas `python`

**Tests problÃ©matiques connus :**
- 8 tests V2 Ã©chouent (caching et validation de conflits) - bugs prÃ©-existants
- `test_config_selector.py` - Peut bloquer (tests CLI interactive avec input() mockÃ©)

### Code Quality Tools

Le projet utilise plusieurs outils d'analyse de code pour maintenir la qualitÃ© :

**Outils installÃ©s** (dans `CLI/pyproject.toml`, section `[project.optional-dependencies].dev`) :
- `flake8` - Style checker (PEP 8)
- `radon` - Analyseur de complexitÃ© cyclomatique
- `vulture` - DÃ©tecteur de code mort
- `bandit` - Scanner de sÃ©curitÃ©
- `mypy` - Type checker (statique)

**Installation des outils :**
```bash
# Les outils sont dÃ©jÃ  rÃ©fÃ©rencÃ©s dans CLI/pyproject.toml
# Installer directement :
venv/bin/pip install flake8 radon vulture bandit mypy
```

**Commandes d'analyse :**

```bash
# Depuis la racine du projet

# 1. Style checking (PEP 8)
venv/bin/python3 -m flake8 CLI \
  --exclude=tests,__pycache__,private_generators,example_* \
  --max-line-length=120 \
  --count --statistics

# 2. ComplexitÃ© cyclomatique
# -a : moyenne, -nb : pas de note globale
venv/bin/python3 -m radon cc CLI \
  --exclude="tests,__pycache__,private_generators,example_*" \
  -a -nb

# 3. Code mort (dead code)
cd CLI && ../venv/bin/python3 -m vulture . \
  --min-confidence=80 2>&1 | \
  grep -v "tests/" | grep -v "example_"

# 4. SÃ©curitÃ©
# -r : recursif, -ll : low/low severity (moins verbeux)
venv/bin/python3 -m bandit -r CLI -ll -f txt

# 5. Type checking (optionnel, peut Ãªtre verbeux)
venv/bin/python3 -m mypy CLI --ignore-missing-imports
```

**Analyse complÃ¨te :**
```bash
# Lancer tous les checks d'un coup
cd /mnt/d/StableDiffusion/local-sd-generator
venv/bin/python3 -m flake8 CLI --exclude=tests,private_generators --max-line-length=120 && \
venv/bin/python3 -m radon cc CLI --exclude="tests,private_generators" -a && \
echo "âœ“ Quality checks passed"
```

**Seuils de complexitÃ© (radon) :**
- **A (1-5)** : Simple âœ…
- **B (6-10)** : ModÃ©rÃ© âœ… (acceptable)
- **C (11-20)** : Complexe ğŸŸ¡ (Ã  surveiller)
- **D (21-30)** : TrÃ¨s complexe ğŸŸ  (refactor recommandÃ©)
- **E (31-40)** : ExtrÃªmement complexe ğŸ”´ (refactor urgent)
- **F (41+)** : Non maintenable ğŸ’€ (refactor immÃ©diat)

**Rapports d'analyse :**
- Voir `docs/tooling/code_review_2025-10-06.md` pour la derniÃ¨re code review manuelle
- Voir `docs/tooling/automated_metrics_2025-10-06.md` pour les mÃ©triques objectives

## ğŸ“– Documentation Guidelines

### ğŸ“ Structure de la documentation

```
docs/
â”œâ”€â”€ cli/          # Documentation CLI
â”‚   â”œâ”€â”€ usage/    # Guides utilisateur
â”‚   â””â”€â”€ technical/ # Documentation technique
â”œâ”€â”€ front/        # Documentation Frontend
â”œâ”€â”€ api/          # Documentation API
â”œâ”€â”€ tooling/      # Documentation outils dev
â””â”€â”€ roadmap/      # Planning des features
    â”œâ”€â”€ done/     # Features terminÃ©es
    â”œâ”€â”€ wip/      # En cours
    â”œâ”€â”€ next/     # Prochaines tÃ¢ches
    â””â”€â”€ future/   # Backlog futur
```

### ğŸ“ Quand travailler sur une feature

#### 1. **Avant de commencer**
- CrÃ©er ou dÃ©placer la spec dans `docs/roadmap/wip/`
- La spec doit contenir :
  - **Status** : wip
  - **Priority** : 1-10
  - **Description** : Quoi et pourquoi
  - **Implementation** : Approche technique
  - **Tasks** : Liste dÃ©taillÃ©e des tÃ¢ches
  - **Success Criteria** : CritÃ¨res de complÃ©tion
  - **Tests** : Plan de tests

#### 2. **Pendant le dÃ©veloppement**
- Maintenir la doc technique Ã  jour dans `docs/{cli|front|api|tooling}/technical/`
- Documenter les dÃ©cisions importantes :
  - Pourquoi tel choix plutÃ´t qu'un autre ?
  - Quels trade-offs ont Ã©tÃ© faits ?
  - Quelles alternatives ont Ã©tÃ© considÃ©rÃ©es ?
- Ajouter des exemples d'usage dans `docs/{cli|front|api|tooling}/usage/` au fur et Ã  mesure

#### 3. **Quand c'est terminÃ©**
- DÃ©placer la spec de `wip/` vers `done/`
- Ajouter dans la spec :
  - Date de complÃ©tion
  - Nombre de tests et leur statut
  - Hash des commits principaux
  - Liens vers la doc technique/usage
- Mettre Ã  jour la doc utilisateur si nÃ©cessaire
- VÃ©rifier que l'architecture est documentÃ©e dans `technical/`
- Mettre Ã  jour le `README.md` du composant si nouveaux concepts

### ğŸ¯ Contenu des specs roadmap

Chaque fichier dans `roadmap/{done|wip|next|future}/` doit suivre ce template :

```markdown
# Feature Name

**Status:** done|wip|next|future
**Priority:** 1-10
**Component:** cli|front|api|tooling
**Created:** YYYY-MM-DD
**Completed:** YYYY-MM-DD (si done)

## Description
Quoi et pourquoi...

## Implementation
Approche technique...

## Tasks
- [ ] Task 1
- [ ] Task 2

## Success Criteria
- CritÃ¨re 1
- CritÃ¨re 2

## Tests
- X tests unitaires
- Y tests d'intÃ©gration

## Documentation
- Usage: docs/cli/usage/xxx.md
- Technical: docs/cli/technical/xxx.md

## Commits (si done)
- abc1234: commit message
```

### ğŸ”„ Lifecycle des features

```
future/ â†’ next/ â†’ wip/ â†’ done/
```

### ğŸ“Š Priorities

- **1-3** : Critique (sprint actuel)
- **4-6** : Important (prochain sprint)
- **7-8** : Nice-to-have (futur)
- **9-10** : Recherche/expÃ©rimental

## ğŸ” Code Review Guidelines

Avant de commencer une code review, consulter ces documents :

### Documents de rÃ©fÃ©rence
- **[Code Review Guidelines](docs/tooling/CODE_REVIEW_GUIDELINES.md)** - Directives complÃ¨tes pour les code reviews
  - Principes SOLID et architecture
  - QualitÃ© du code (complexitÃ©, lisibilitÃ©, DRY)
  - Organisation et documentation
  - Performance et sÃ©curitÃ©
  - Checklist par fichier (~30-35 min)
  - Red flags et problÃ¨mes courants

- **[Code Review Action Templates](docs/tooling/CODE_REVIEW_ACTION_TEMPLATES.md)** - Templates pour actions post-review
  - 6 templates de fiches d'action dÃ©taillÃ©s
  - Matrice de priorisation (CriticitÃ© Ã— Effort)
  - Workflows d'exÃ©cution (simple/complexe)
  - Dashboard de suivi et validation
  - Templates GitHub Issues et communication

### Processus de code review

**Phase 1 : Review**
1. Lire les guidelines dans `CODE_REVIEW_GUIDELINES.md`
2. Reviewer les fichiers avec la checklist
3. Identifier les problÃ¨mes (ğŸ”´ Bloquant, ğŸŸ  Important, ğŸŸ¡ Suggestion, ğŸ’¡ Question)

**Phase 2 : Actions**
1. CrÃ©er fiches d'action avec templates appropriÃ©s
2. Prioriser selon matrice (P1-P5)
3. Planifier dans sprints

**Phase 3 : ExÃ©cution**
1. Suivre workflows selon taille (Small/Medium/Large)
2. Tracker progrÃ¨s avec dashboard
3. Valider avec checklist avant fermeture

### Outils automatiques recommandÃ©s
```bash
# Style et qualitÃ©
flake8 CLI/ --max-line-length=120
mypy CLI/ --strict

# ComplexitÃ©
radon cc CLI/ -a -nb

# Code mort
vulture CLI/

# SÃ©curitÃ©
bandit -r CLI/
```

## ğŸš€ CLI Usage

### Generate images from template

```bash
# Interactive mode (liste les templates disponibles)
python3 src/cli.py generate

# Direct template
python3 src/cli.py generate -t path/to/template.prompt.yaml

# Limit number of images
python3 src/cli.py generate -t template.yaml -n 50

# Dry-run (save API payloads as JSON without generating)
python3 src/cli.py generate -t template.yaml --dry-run
```

### Other commands

```bash
# List all available templates
python3 src/cli.py list

# Validate a template file
python3 src/cli.py validate path/to/template.yaml

# Initialize global config
python3 src/cli.py init

# API introspection
python3 src/cli.py api samplers
python3 src/cli.py api schedulers
python3 src/cli.py api models
python3 src/cli.py api upscalers
python3 src/cli.py api model-info
```

## ğŸ“¦ Project Status

**Current version:** V2.0 (stable)
**Template system:** V2.0 only (V1 removed)
**Tests:** 306 total (98% pass rate)
**Last major migration:** 2025-10-10 (V1â†’V2 complete)

## Commands
- **Lint:** `flake8 CLI/ --max-line-length=120`
- **Test:** `python3 -m pytest tests/ --ignore=tests/legacy -v`
- **Coverage:** `python3 -m pytest tests/v2/ --cov=templating --cov-report=term-missing`
- **Build:** Ã€ dÃ©terminer
